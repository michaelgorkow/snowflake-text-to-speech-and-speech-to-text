{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "3axbjxdxjdq2gxhowj75",
   "authorId": "61864603178",
   "authorName": "ADMIN",
   "authorEmail": "michael.gorkow@snowflake.com",
   "sessionId": "49b7c522-1fd3-4e35-8b92-7be718283299",
   "lastEditTime": 1755867119716
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e8d535-b9bb-4c41-8b82-d695fdddabfd",
   "metadata": {
    "collapsed": false,
    "name": "TITLE"
   },
   "source": [
    "# Text to Speech in Snowflake\n",
    "This notebook walks you through the following steps:\n",
    "* Define a custom model for Facebook's TTS models from their [Massive Multilingual Speech project](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/).\n",
    "* Register the model in Snowflake's model registry\n",
    "* Deploy the model as an inference service using Snowpark Container Services\n",
    "* Test the deployed inference service\n",
    "* View Service Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1e9f8-5b80-49bf-a422-34ab599be30a",
   "metadata": {
    "collapsed": false,
    "name": "CONNECTION1"
   },
   "source": [
    "## Create Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "CONNECTION2"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9e73d-eae6-4a6d-8ed8-7fb5a0d53a3e",
   "metadata": {
    "collapsed": false,
    "name": "DEFINE_MODEL1"
   },
   "source": [
    "## Define Model\n",
    "We'll be hosting multiple models on a single GPU, given that these models are fairly small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152ff24-8bd1-463a-b1c8-bfd88ed7807a",
   "metadata": {
    "language": "python",
    "name": "DEFINE_MODEL2"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, VitsModel, pipeline\n",
    "import torch\n",
    "\n",
    "def load_pipeline(model_id):\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float32 if torch.cuda.is_available() else torch.float32\n",
    "    \n",
    "    model = VitsModel.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch_dtype,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_safetensors=True\n",
    "    ).to(device)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    model_pipeline = pipeline(\n",
    "        \"text-to-speech\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    return model_pipeline\n",
    "\n",
    "lang_codes = ['eng','deu','fra','nld','hin','kor','pol','por','rus','spa','swe']\n",
    "\n",
    "pipelines = {}\n",
    "for code in lang_codes:\n",
    "    pipelines[code] = load_pipeline(f'facebook/mms-tts-{code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb10190-e308-4536-abec-bb02aef1a679",
   "metadata": {
    "collapsed": false,
    "name": "CUSTOM_MODEL1"
   },
   "source": [
    "## Create Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b37b91-6d7c-4059-852e-4ac9a52ed116",
   "metadata": {
    "language": "python",
    "name": "CUSTOM_MODEL2"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.model import custom_model\n",
    "import numpy as np\n",
    "import scipy\n",
    "import io\n",
    "import logging\n",
    "import base64\n",
    "\n",
    "class TextToSpeechModel(custom_model.CustomModel):\n",
    "    def __init__(self, context: custom_model.ModelContext) -> None:\n",
    "        super().__init__(context)\n",
    "        warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "        # Set up a logger\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.logger.handlers.clear()\n",
    "\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "\n",
    "    def run_pipeline(self, text, lang_code):\n",
    "        lang_code = lang_code.lower()\n",
    "        self.logger.debug(f\"Starting text to speech processing language={lang_code}...\")\n",
    "        # retrieve pipeline given the lang_code\n",
    "        pipeline_code = f'pipeline_{lang_code}'\n",
    "        output = self.context[pipeline_code](text)\n",
    "        waveform = output[\"audio\"]\n",
    "        sampling_rate = output[\"sampling_rate\"]\n",
    "        # Ensure valid shape\n",
    "        if waveform.ndim == 2:\n",
    "            # Convert to mono (average channels)\n",
    "            waveform = waveform.mean(axis=0)\n",
    "        # Ensure waveform is float32 in range [-1.0, 1.0]\n",
    "        waveform = np.asarray(waveform, dtype=np.float32)\n",
    "        waveform = np.clip(waveform, -1.0, 1.0)\n",
    "        # Convert to int16 for WAV format\n",
    "        waveform_int16 = (waveform * 32767).astype(np.int16)\n",
    "        # Write waveform to buffer\n",
    "        buffer = io.BytesIO()\n",
    "        scipy.io.wavfile.write(buffer, rate=sampling_rate, data=waveform_int16)\n",
    "        buffer.seek(0)\n",
    "        audio_bytes = buffer.getvalue()\n",
    "        # Encode audio into base64 (to make them JSON serializable)\n",
    "        audio_base64_bytes = base64.b64encode(audio_bytes).decode('utf-8')\n",
    "        self.logger.debug(f\"Finished text to speech processing language={lang_code}...\")\n",
    "        return audio_base64_bytes\n",
    "\n",
    "    @custom_model.inference_api\n",
    "    def transform(self, text_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        audio_results = text_df.apply(lambda x: self.run_pipeline(x['TEXT_INPUT'], x['LANG_CODE']), axis=1)\n",
    "        result = pd.DataFrame({'TEXT_TO_SPEECH_RESULT':audio_results})\n",
    "        return result\n",
    "\n",
    "# Set the model context that includes the model pipeline\n",
    "mc = custom_model.ModelContext(\n",
    "    pipeline_eng = pipelines['eng'], \n",
    "    pipeline_deu = pipelines['deu'], \n",
    "    pipeline_fra = pipelines['fra'],\n",
    "    pipeline_nld = pipelines['nld'],\n",
    "    pipeline_hin = pipelines['hin'],\n",
    "    pipeline_kor = pipelines['kor'],\n",
    "    pipeline_pol = pipelines['pol'],\n",
    "    pipeline_por = pipelines['por'],\n",
    "    pipeline_rus = pipelines['rus'],\n",
    "    pipeline_spa = pipelines['spa'],\n",
    "    pipeline_swe = pipelines['swe']\n",
    ")\n",
    "text_to_speech_model = TextToSpeechModel(context=mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d769ad9-b27e-4dc7-b9e8-b69b949d0f48",
   "metadata": {
    "collapsed": false,
    "name": "TEST_MODEL1"
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187caeb-bdfc-46eb-a3b8-3d6081108a01",
   "metadata": {
    "language": "python",
    "name": "TEST_MODEL2"
   },
   "outputs": [],
   "source": [
    "text = [\n",
    "    ['It is so awesome to have text to speech capabilities inside Snowflake!','eng'],\n",
    "    ['Es ist so cool Text in Sprache in Snowflake umwandeln zu können!','deu'],\n",
    "    [\"C'est tellement génial d'avoir des fonctionnalités de synthèse vocale directement dans Snowflake!\",'fra']\n",
    "]\n",
    "\n",
    "input_df = pd.DataFrame(text, columns=['TEXT_INPUT','LANG_CODE'])\n",
    "output_df = text_to_speech_model.transform(input_df)\n",
    "\n",
    "st.dataframe(output_df)\n",
    "\n",
    "audio_bytes = output_df.iloc[2]['TEXT_TO_SPEECH_RESULT']\n",
    "decoded_audio = base64.b64decode(audio_bytes)\n",
    "st.audio(decoded_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1609fa-2a9a-4e9c-93ca-adc217bbf146",
   "metadata": {
    "language": "python",
    "name": "TEST_MODEL3"
   },
   "outputs": [],
   "source": [
    "# Listen to results\n",
    "for ix, row in pd.concat([input_df, output_df], axis=1).iterrows():\n",
    "    audio_bytes = base64.b64decode(row['TEXT_TO_SPEECH_RESULT'])\n",
    "    with st.chat_message('ai'):\n",
    "        st.markdown(f\"## Lang Code: {row['LANG_CODE']}\")\n",
    "        st.write(row['TEXT_INPUT'])\n",
    "        st.audio(audio_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb528297-acf9-4344-83e5-71d67ba27107",
   "metadata": {
    "collapsed": false,
    "name": "REGISTER_MODEL1"
   },
   "source": [
    "## Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf2689-7b20-4f2b-b92e-857a7593cdf9",
   "metadata": {
    "language": "sql",
    "name": "REGISTER_MODEL2"
   },
   "outputs": [],
   "source": [
    "CREATE SCHEMA IF NOT EXISTS MODEL_REGISTRY;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ff358-ca62-44ed-86a9-6336de98a1b8",
   "metadata": {
    "language": "python",
    "name": "REGISTER_MODEL3"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.model.model_signature import infer_signature\n",
    "\n",
    "reg = Registry(session=session, database_name=\"AUDIO_INTERFACING_DEMO\", schema_name=\"MODEL_REGISTRY\")\n",
    "\n",
    "model_signature = infer_signature(input_data=input_df, output_data=output_df)\n",
    "print(model_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffe33f-eda7-49e1-9521-2072032e70ce",
   "metadata": {
    "language": "python",
    "name": "REGISTER_MODEL4"
   },
   "outputs": [],
   "source": "model_ref = reg.log_model(\n    model_name=\"TEXT_TO_SPEECH\",\n    version_name=\"MULTILANGUAGE\",    \n    model=text_to_speech_model,\n    #pip_requirements=['torch'],\n    signatures={\"transform\": model_signature},\n    options={\"use_gpu\": True, \"cuda_version\": \"11.8\"},\n    comment=\"facebook/mms-tts-models ['eng','deu','fra','nld','hin','kor','pol','por','rus','spa','swe']\"\n)"
  },
  {
   "cell_type": "markdown",
   "id": "f7bce56a-d7e3-4afe-8a7f-f2382d4e97f9",
   "metadata": {
    "collapsed": false,
    "name": "CREATE_SERVICE1"
   },
   "source": [
    "## Create Inference Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40fa4a-aa72-4fea-ad27-2fd304fa247e",
   "metadata": {
    "language": "python",
    "name": "CREATE_SERVICE2"
   },
   "outputs": [],
   "source": "# mv is a snowflake.ml.model.ModelVersion object\ninference_service = model_ref.create_service(\n    service_name=\"AUDIO_INTERFACING_DEMO.PUBLIC.TEXT_TO_SPEECH\",\n    service_compute_pool=\"AUDIO_INTERFACE_GPU_POOL\",\n    ingress_enabled=True,\n    gpu_requests='1'\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e7a24-574e-4f7f-86de-41937aab4a2f",
   "metadata": {
    "language": "python",
    "name": "CREATE_SERVICE3"
   },
   "outputs": [],
   "source": [
    "model_ref.list_services()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb7d7f-afc4-4fb1-b4ac-637e621180c1",
   "metadata": {
    "collapsed": false,
    "name": "TEST_SERVICE1"
   },
   "source": [
    "## Test Inference Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff7fff-2702-4a97-b6cd-6b0222f20d34",
   "metadata": {
    "language": "python",
    "name": "TEST_SERVICE2"
   },
   "outputs": [],
   "source": [
    "text = [\n",
    "    ['It is so awesome to have text to speech capabilities inside Snowflake!','eng'],\n",
    "    ['Es ist so cool Text in Sprache in Snowflake umwandeln zu können!','deu'],\n",
    "    [\"C'est tellement génial d'avoir des fonctionnalités de synthèse vocale directement dans Snowflake!\",'fra']\n",
    "]\n",
    "\n",
    "input_df = pd.DataFrame(text, columns=['TEXT_INPUT','LANG_CODE'])\n",
    "\n",
    "output_df = model_ref.run(\n",
    "    input_df,\n",
    "    function_name=\"transform\",\n",
    "    service_name=\"AUDIO_INTERFACING_DEMO.PUBLIC.TEXT_TO_SPEECH\"\n",
    ")\n",
    "\n",
    "st.dataframe(output_df)\n",
    "\n",
    "# Listen to results\n",
    "for ix, row in pd.concat([input_df, output_df], axis=1).iterrows():\n",
    "    audio_bytes = base64.b64decode(row['TEXT_TO_SPEECH_RESULT'])\n",
    "    with st.chat_message('ai'):\n",
    "        st.markdown(f\"## Lang Code: {row['LANG_CODE']}\")\n",
    "        st.write(row['TEXT_INPUT'])\n",
    "        st.audio(audio_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b282680-211c-4cec-a657-93590a4b2c3d",
   "metadata": {
    "collapsed": false,
    "name": "SQL_INTERFACE1"
   },
   "source": [
    "## Inference with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e26e1-af0f-48ef-aaa1-0c239e7560dc",
   "metadata": {
    "language": "sql",
    "name": "SQL_INTERFACE2"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    -- call the model\n",
    "    AUDIO_INTERFACING_DEMO.PUBLIC.TEXT_TO_SPEECH!transform('Snowflake is awesome.','eng') AS MODEL_OUTPUT,\n",
    "    -- retrieve the base64 string\n",
    "    MODEL_OUTPUT['TEXT_TO_SPEECH_RESULT'] AS MODEL_OUTPUT_BASE64,\n",
    "    -- Decode it to binary\n",
    "    BASE64_DECODE_BINARY(MODEL_OUTPUT_BASE64) AS MODEL_OUTPUT_BINARY;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30883234-e941-4552-ad48-beb0b6703728",
   "metadata": {
    "language": "python",
    "name": "SQL_INTERFACE3"
   },
   "outputs": [],
   "source": [
    "# Get the data from the former cell and play it\n",
    "st.audio(SQL_INTERFACE2.to_pandas().iloc[0]['MODEL_OUTPUT_BINARY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73289799-a076-42a1-8f04-b5b14f880039",
   "metadata": {
    "collapsed": false,
    "name": "LOGS1"
   },
   "source": [
    "## View Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0ccd6-dd22-47cf-897f-bb6e5fa60dbf",
   "metadata": {
    "language": "python",
    "name": "LOGS2"
   },
   "outputs": [],
   "source": [
    "logs = session.call('SYSTEM$GET_SERVICE_LOGS', 'AUDIO_INTERFACING_DEMO.PUBLIC.TEXT_TO_SPEECH', '0', 'model-inference')\n",
    "for line in logs.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef30c99-bff9-41d2-b327-273338a4325f",
   "metadata": {
    "collapsed": false,
    "name": "END"
   },
   "source": [
    "## END"
   ]
  }
 ]
}